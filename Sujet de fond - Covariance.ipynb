{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création de la fonction de calcul d'espérance\n",
    "def portfolio(ppc=0.6, ph=0.5, rh=1, rb=-2, N_indice=100, n_bigcap=5, w_bigcap=0.1, N_ptf=30, x=0.05, y=0.1, indice = False):\n",
    "    \n",
    "    if indice == False:\n",
    "        # Espérance des Small Cap\n",
    "        E_R_sc_adjusted = smallcap_ptf(ppc=ppc, ph=ph, rh=rh, rb=rb, N_indice=N_indice, n_bigcap=n_bigcap, w_bigcap=w_bigcap, N_ptf=N_ptf, x=x, y=y)[0]\n",
    "\n",
    "        # Espérance des Big Cap \n",
    "        E_R_bc_total = bigcap(ppc=ppc, ph=ph, rh=rh, rb=rb, N_indice=N_indice, n_bigcap=n_bigcap, w_bigcap=w_bigcap, N_ptf=N_ptf, x=x, y=y)[0]\n",
    "\n",
    "        # Espérance du portefeuille\n",
    "        E_R = E_R_sc_adjusted + E_R_bc_total\n",
    "\n",
    "        # Variance du small cap\n",
    "        Var_R_sc_adjusted = smallcap_ptf(ppc=ppc, ph=ph, rh=rh, rb=rb, N_indice=N_indice, n_bigcap=n_bigcap, w_bigcap=w_bigcap, N_ptf=N_ptf, x=x, y=y)[1]\n",
    "\n",
    "        # Variance du big cap\n",
    "        Var_R_bc_total = bigcap(ppc=ppc, ph=ph, rh=rh, rb=rb, N_indice=N_indice, n_bigcap=n_bigcap, w_bigcap=w_bigcap, N_ptf=N_ptf, x=x, y=y)[1]\n",
    "        \n",
    "        E_R_sc_ptf_correct = ((ph * ppc)/(ph * ppc + (1 - ph) * (1 - ppc))) * rh\n",
    "        E_R_sc_ptf_incorrect = (1 - ((ph * ppc)/(ph * ppc + (1 - ph) * (1 - ppc)))) * rb \n",
    "        E_R_sc_ptf_total = (E_R_sc_ptf_correct + E_R_sc_ptf_incorrect) #* 1/n_smallcap_ptf * n_smallcap_ptf\n",
    "\n",
    "        term1 = ph * (ppc * (w_bigcap + x) * (1 - (w_bigcap + x)) + (1 - ppc) * (w_bigcap - y) * (1 - (w_bigcap - y))) * rh * (1 - n_bigcap * (w_bigcap + ((ph * ppc + (1 - ph) * (1 - ppc)) * x - (ph * (1 - ppc) + (1 - ph) * ppc) * y)))\n",
    "        term2 = (1 - ph) * (ppc * (w_bigcap - y) * (1 - (w_bigcap - y)) + (1 - ppc) * (w_bigcap + x) * (1 - (w_bigcap + x))) * rb * (1 - n_bigcap * (w_bigcap + ((ph * ppc + (1 - ph) * (1 - ppc)) * x - (ph * (1 - ppc) + (1 - ph) * ppc) * y)))\n",
    "\n",
    "        result = (term1 + term2) * n_bigcap\n",
    "\n",
    "        Cov_R_sc_bc = E_R_sc_ptf_total * result - E_R_sc_adjusted * E_R_bc_total\n",
    "        # Variance du portefeuille\n",
    "        #Var_R = Var_R_sc_adjusted + Var_R_bc_total + 2 * Cov_R_sc_bc\n",
    "        Var_R = Var_R_sc_adjusted * E_R_bc_total + Var_R_bc_total * E_R_sc_adjusted + Var_R_sc_adjusted * Var_R_bc_total\n",
    "    \n",
    "    else:\n",
    "        # Espérance des Small Cap\n",
    "        E_R_sc_adjusted = smallcap_indice(ppc=ppc, ph=ph, rh=rh, rb=rb, N_indice=N_indice, n_bigcap=n_bigcap, w_bigcap=w_bigcap, N_ptf=N_ptf, x=x, y=y)[0]\n",
    "\n",
    "        # Espérance des Big Cap \n",
    "        E_R_bc_total = bigcap(ppc=ppc, ph=ph, rh=rh, rb=rb, N_indice=N_indice, n_bigcap=n_bigcap, w_bigcap=w_bigcap, N_ptf=N_ptf, x=x, y=y)[0]\n",
    "\n",
    "        # Espérance du portefeuille\n",
    "        E_R = E_R_sc_adjusted + E_R_bc_total\n",
    "\n",
    "        # Variance du small cap\n",
    "        Var_R_sc_adjusted = smallcap_indice(ppc=ppc, ph=ph, rh=rh, rb=rb, N_indice=N_indice, n_bigcap=n_bigcap, w_bigcap=w_bigcap, N_ptf=N_ptf, x=x, y=y)[1]\n",
    "\n",
    "        # Variance du big cap\n",
    "        Var_R_bc_total = bigcap(ppc=ppc, ph=ph, rh=rh, rb=rb, N_indice=N_indice, n_bigcap=n_bigcap, w_bigcap=w_bigcap, N_ptf=N_ptf, x=x, y=y)[1]\n",
    "\n",
    "        # Variance du portefeuille\n",
    "        Var_R = Var_R_sc_adjusted + Var_R_bc_total\n",
    "\n",
    "        result = 0\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return E_R, Var_R, result\n",
    "\n",
    "def bigcap(ppc=0.6, ph=0.5, rh=1, rb=-2, N_indice=100, n_bigcap=5, w_bigcap=0.1, N_ptf=30, x=0.05, y=0.1):\n",
    "    # Espérance des Big Cap \n",
    "    E_R_bc_correct = ph * (ppc * (w_bigcap + x) + (1 - ppc) * (w_bigcap - y)) * rh  # Correct prediction outcomes\n",
    "    E_R_bc_incorrect = (1 - ph) * (ppc * (w_bigcap - y) + (1 - ppc) * (w_bigcap + x)) * rb  # Incorrect prediction outcomes\n",
    "    E_R_bc = (E_R_bc_correct + E_R_bc_incorrect)\n",
    "    E_R_bc_total = E_R_bc * n_bigcap\n",
    "    \n",
    "\n",
    "    # Variance des Big Cap\n",
    "    Var_R_bc = (ph * (rh)**2 * (ppc * (w_bigcap + x)**2 + (1 - ppc) * (w_bigcap - y)**2) + (1 - ph) * (rb)**2 * (ppc * (w_bigcap - y)**2 + (1 - ppc) * (w_bigcap + x)**2)) - E_R_bc**2\n",
    "    Var_R_bc_total = Var_R_bc * n_bigcap\n",
    "\n",
    "    return E_R_bc_total, Var_R_bc_total\n",
    "\n",
    "def smallcap_ptf(ppc=0.6, ph=0.5, rh=1, rb=-2, N_indice=100, n_bigcap=5, w_bigcap=0.1, N_ptf=30, x=0.05, y=0.1):\n",
    "    # Espérance des Small Cap\n",
    "    E_R_sc_ptf_correct = ((ph * ppc)/(ph * ppc + (1 - ph) * (1 - ppc))) * rh\n",
    "    E_R_sc_ptf_incorrect = (1 - ((ph * ppc)/(ph * ppc + (1 - ph) * (1 - ppc)))) * rb \n",
    "    E_R_sc_ptf_total = (E_R_sc_ptf_correct + E_R_sc_ptf_incorrect) #* 1/n_smallcap_ptf * n_smallcap_ptf\n",
    "    \n",
    "    # Variance des Small Cap\n",
    "    #Var_X_sc_ptf = ((ph * ppc)/(ph * ppc + (1 - ph) * (1 - ppc))) * ((rh - E_X_sc_ptf_total) ** 2) + (1 - ((ph * ppc)/(ph * ppc + (1 - ph) * (1 - ppc)))) * ((rb - E_X_sc_ptf_total) ** 2)\n",
    "    Var_R_sc_ptf = ((((ph * ppc)/(ph * ppc + (1 - ph) * (1 - ppc))) * ((rh) ** 2) + (1 - ((ph * ppc)/(ph * ppc + (1 - ph) * (1 - ppc)))) * ((rb) ** 2)) - E_R_sc_ptf_total**2)\n",
    "    Var_R_sc_ptf_N = Var_R_sc_ptf / (N_ptf - n_bigcap)\n",
    "\n",
    "    # Espérance de l'ajustement\n",
    "    E_X_ajustement = (ph * ppc + (1 - ph) * (1 - ppc)) * x - (ph * (1 - ppc) + (1 - ph) * ppc) * y\n",
    "    E_W_sc = 1 - n_bigcap * (w_bigcap + E_X_ajustement)\n",
    "\n",
    "    # Variance de l'ajustement\n",
    "    Var_X_ajustement = (ph * ppc + (1 - ph) * (1 - ppc)) * (x - E_X_ajustement)**2 + (ph * (1 - ppc) + (1 - ph) * ppc) * (-y - E_X_ajustement)**2\n",
    "    Var_W_sc = Var_X_ajustement * n_bigcap\n",
    "\n",
    "    # Espérance ajustée pour les rendements \"Small Cap\" en prenant en compte l'ajustement de poids\n",
    "    E_R_sc_ptf_adj = E_R_sc_ptf_total * E_W_sc\n",
    "\n",
    "    # Variance ajustée pour les rendements \"Small Cap\" en prenant en compte l'ajustement de poids\n",
    "    Var_R_sc_ptf_adj = Var_R_sc_ptf_N * E_W_sc**2 + Var_W_sc * E_R_sc_ptf_total**2 + Var_W_sc * Var_R_sc_ptf_N\n",
    "\n",
    "    return E_R_sc_ptf_adj, Var_R_sc_ptf_adj, E_R_sc_ptf_total\n",
    "\n",
    "def smallcap_indice(ppc=0.6, ph=0.5, rh=1, rb=-2, N_indice=100, n_bigcap=5, w_bigcap=0.1, N_ptf=30, x=0.05, y=0.1):\n",
    "    \n",
    "    # Espérance des Small Cap de l'indice\n",
    "    E_R_sc_correct_indice = ph * rh\n",
    "    E_R_sc_incorrect_indice = (1 - ph) * rb\n",
    "    E_R_sc_total_indice = (E_R_sc_correct_indice + E_R_sc_incorrect_indice)\n",
    "    E_R_sc_total_indice_adj = E_R_sc_total_indice * (1 - n_bigcap * w_bigcap)\n",
    "\n",
    "    # Variance des Small Cap de l'indice\n",
    "    Var_R_sc_indice = (ph * (rh)**2 + (1 - ph) * (rb)**2) - E_R_sc_total_indice**2\n",
    "    Var_R_sc_indice_total = Var_R_sc_indice / (N_indice - n_bigcap)\n",
    "    Var_R_sc_indice_adj = Var_R_sc_indice_total * (1 - n_bigcap * w_bigcap)**2\n",
    "\n",
    "    return E_R_sc_total_indice_adj, Var_R_sc_indice_adj\n",
    "\n",
    "def ajustement(ppc=0.6, ph=0.5, rh=1, rb=-2, N_indice=100, n_bigcap=5, w_bigcap=0.1, N_ptf=30, x=0.05, y=0.1):\n",
    "    # Espérance de l'ajustement\n",
    "    E_x_ajustement = (ph * ppc + (1 - ph) * (1 - ppc)) * x - (ph * (1 - ppc) + (1 - ph) * ppc) * y\n",
    "    E_x_total = E_x_ajustement * n_bigcap\n",
    "\n",
    "    # Variance de l'ajustement\n",
    "    Var_x_ajustement = (ph * ppc + (1 - ph) * (1 - ppc)) * (x - E_x_ajustement)**2 + (ph * (1 - ppc) + (1 - ph) * ppc) * (-y - E_x_ajustement)**2\n",
    "    Var_x_ajustement_total = Var_x_ajustement * n_bigcap\n",
    "    return E_x_ajustement, E_x_total, Var_x_ajustement, Var_x_ajustement_total\n",
    "\n",
    "#Création de la fonction de simulation\n",
    "def simulate_portfolio(ppc=0.6, ph=0.5, rh=1, rb=-2, N_indice=100, n_bigcap=5, w_bigcap=0.1, N_ptf=30, x=0.05,y=0.1):\n",
    "    n_smallcap_indice = N_indice - n_bigcap\n",
    "    exposition_smallcap_indice = 1 - n_bigcap * w_bigcap\n",
    "    w_smallcap_indice = exposition_smallcap_indice/1/n_smallcap_indice\n",
    "    n_smallcap_ptf = N_ptf - n_bigcap\n",
    "\n",
    "    returns = np.random.choice([rh, rb], size=(N_indice,), p=[ph, (1 - ph)])\n",
    "    actions_momentum = np.where(returns == rh, 1, 0)\n",
    "    probas = [ppc, (1 - ppc)]\n",
    "    actions_momentum_pred = np.where(actions_momentum == 1, \n",
    "                                     np.random.choice([1, 0], size=N_indice, p=probas), \n",
    "                                     np.random.choice([0, 1], size=N_indice, p=probas))\n",
    "    actions = np.arange(N_indice)\n",
    "\n",
    "    df_bigcap_indice = pd.DataFrame({'Actions':actions[:n_bigcap],'Returns':returns[:n_bigcap],'Momentum':actions_momentum[:n_bigcap],'Momentum_pred':actions_momentum_pred[:n_bigcap], 'Poids':w_bigcap})\n",
    "    df_smallcap_indice = pd.DataFrame({'Actions':actions[n_bigcap:],'Returns':returns[n_bigcap:],'Momentum':actions_momentum[n_bigcap:],'Momentum_pred':actions_momentum_pred[n_bigcap:], 'Poids':w_smallcap_indice})\n",
    "    df_indice = pd.concat([df_bigcap_indice, df_smallcap_indice])\n",
    "    return_indice = np.sum(df_indice['Returns'] * df_indice['Poids'])\n",
    "\n",
    "    df_bigcap_ptf = df_bigcap_indice.copy().assign(Poids = lambda df: df[\"Poids\"] + df[\"Momentum_pred\"].map({1: x, 0: -y}))\n",
    "    df_smallcap_ptf = df_smallcap_indice.sort_values(by='Momentum_pred',ascending=False).head(n_smallcap_ptf).assign(Poids = (1 - df_bigcap_ptf['Poids'].sum())/1/n_smallcap_ptf)\n",
    "    df_ptf = pd.concat([df_bigcap_ptf, df_smallcap_ptf])\n",
    "    return_ptf = np.sum(df_ptf['Returns'] * df_ptf['Poids'])\n",
    "\n",
    "    delta_return = return_ptf - return_indice \n",
    "\n",
    "    # Finding a problem with the weights\n",
    "\n",
    "\n",
    "    return_bigcap_ptf = np.sum(df_bigcap_ptf['Returns'] * df_bigcap_ptf['Poids'])\n",
    "    return_bigcap_indice = np.sum(df_bigcap_indice['Returns'] * df_bigcap_indice['Poids'])\n",
    "    return_smallcap_ptf = np.sum(df_smallcap_ptf['Returns'] * df_smallcap_ptf['Poids'])\n",
    "    return_smallcap_indice = np.sum(df_smallcap_indice['Returns'] * df_smallcap_indice['Poids'])\n",
    "    E_x_total = df_bigcap_ptf['Poids'].sum() - n_bigcap * w_bigcap\n",
    "\n",
    "    W_sc = df_smallcap_ptf['Poids'].sum()\n",
    "    E_WY = return_bigcap_ptf * W_sc\n",
    "    \n",
    "    return return_indice, return_ptf, delta_return, return_bigcap_ptf, return_smallcap_ptf,  return_bigcap_indice, return_smallcap_indice, E_x_total, W_sc, E_WY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fondamentaux du Calcul des Espérances\n",
    "\n",
    "Le calcul des espérances est un concept clé en statistique et en probabilité, offrant une mesure de la tendance centrale d'une distribution de probabilité. Cela représente la valeur moyenne que vous pouvez vous attendre à obtenir d'une variable aléatoire après un grand nombre d'essais. Voici quelques-unes des propriétés fondamentales des espérances :\n",
    "\n",
    "### Définition de l'Espérance\n",
    "\n",
    "Pour une variable aléatoire discrète $X$, prenant des valeurs $x_i$ avec les probabilités correspondantes $p_i$, l'espérance est donnée par :\n",
    "\n",
    "$$\n",
    "E(X) = \\sum_{i} x_i p_i\n",
    "$$\n",
    "\n",
    "où la somme porte sur toutes les valeurs possibles de $X$.\n",
    "\n",
    "### Propriétés Fondamentales de l'Espérance\n",
    "- Espérance d'une Somme\n",
    "$\n",
    "E(X + Y) = E(X) + E(Y)\n",
    "$\n",
    "\n",
    "- Espérance d'un Produit pour des Variables Indépendantes\n",
    "$\n",
    "E(XY) = E(X) \\cdot E(Y) \\quad \\text{si X et Y sont indépendantes}\n",
    "$\n",
    "- Espérance d'une Constante Multiplicative\n",
    "$\n",
    "E(aX) = a \\cdot E(X)\n",
    "$\n",
    "- Linéarité de l'Espérance\n",
    "$\n",
    "E(aX + bY) = aE(X) + bE(Y)\n",
    "$\n",
    "- Espérance d'une Constante\n",
    "$\n",
    "E(a) = a\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fondamentaux du Calcul de Variance\n",
    "\n",
    "La variance est une mesure statistique qui décrit la dispersion des valeurs d'une variable aléatoire par rapport à sa moyenne. En d'autres termes, elle mesure à quel point les valeurs d'un ensemble de données sont éloignées les unes des autres. Voici quelques principes de base et propriétés de la variance qui sont essentiels en statistique et en probabilité.\n",
    "\n",
    "### Définition de la Variance\n",
    "\n",
    "La variance d'une variable aléatoire $X$, notée $Var(X)$ ou $sigma^2_X$, est définie comme l'espérance du carré de l'écart entre $X$ et son espérance $E(X)$ :\n",
    "\n",
    "$$\n",
    "Var(X) = E[(X - E(X))^2]\n",
    "$$\n",
    "$$\n",
    "Var(X) = E(X^2) - E(X)^2\n",
    "$$\n",
    "\n",
    "### Propriétés Fondamentales de la Variance \n",
    "\n",
    "- Variance d'une Constante : \n",
    "$\n",
    "Var(c) = 0\n",
    "$\n",
    "\n",
    "- Variance d'une Variable avec Constante Ajoutée : \n",
    "$\n",
    "Var(X + c) = Var(X)\n",
    "$\n",
    "- Variance d'une Variable Multipliée par une Constante :\n",
    "$\n",
    "Var(aX) = a^2 \\cdot Var(X)\n",
    "$\n",
    "- Variance de la Somme de Variables Indépendantes :\n",
    "$\n",
    "Var(X + Y) = Var(X) + Var(Y) \\quad \\text{si X et Y sont indépendantes}\n",
    "$\n",
    "- Variance de la Somme de Variables Dépendantes :\n",
    "$\n",
    "Var(X + Y) = Var(X) + Var(Y) + 2Cov(X, Y) \\quad \\text{si X et Y sont dépendantes}\n",
    "$\n",
    "- Variance de la Multiplication de Variables Indépendantes :\n",
    "$\n",
    "Var(X \\cdot Y) = E(X)^2 \\times Var(Y) + E(Y)^2 \\times Var(X) + Var(X) + Var(Y) \\quad \\text{si X et Y sont indépendantes}\n",
    "$\n",
    "- Variance de la Multiplication de Variables Dépendantes :\n",
    "$\n",
    "Var(X \\cdot Y) = E(X)^2 \\times Var(Y) + E(Y)^2 \\times Var(X) + Var(X) + Var(Y) + 2 \\times E(X) \\times E(Y) \\times Cov(X, Y) \\quad \\text{si X et Y sont dépendantes}\n",
    "$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fondamentaux du Calcul de Covariance\n",
    "\n",
    "La covariance est une mesure statistique qui évalue le degré auquel deux variables aléatoires varient ensemble. En d'autres termes, elle indique si une augmentation de l'une des variables est associée à une augmentation de l'autre variable (covariance positive), ou si une augmentation de l'une est associée à une diminution de l'autre (covariance négative). Voici quelques concepts de base et propriétés importantes de la covariance.\n",
    "\n",
    "### Définition de la Covariance\n",
    "\n",
    "La covariance entre deux variables aléatoires $X$ et $Y$, notée $Cov(X, Y)$, est définie comme :\n",
    "\n",
    "$$\n",
    "Cov(X, Y) = E[(X - E(X))(Y - E(Y))]\n",
    "$$\n",
    "\n",
    "$$\n",
    "Cov(X, Y) = E(XY) - E(X)E(Y)\n",
    "$$\n",
    "\n",
    "\n",
    "où $E(X)$ et $E(Y)$ sont les espérances (moyennes) de $X$ et $Y$, respectivement.\n",
    "\n",
    "### Propriétés Fondamentales de la Covariance\n",
    "\n",
    "- Covariance et Indépendance :\n",
    "$\n",
    "Cov(X, Y) = 0 \\quad \\text{si X et Y sont indépendantes}\n",
    "$\n",
    "\n",
    "- Covariance d'une Variable avec Elle-même\n",
    "$\n",
    "Cov(X, X) = Var(X)\n",
    "$\n",
    "- Covariance et Constantes :\n",
    "$\n",
    "Cov(X, c) = 0\n",
    "$\n",
    "- Propriété de Symétrie :\n",
    "$\n",
    "Cov(X, Y) = Cov(Y, X)\n",
    "$\n",
    "- Linéarité de la Covariance :\n",
    "$\n",
    "Cov(aX + b, cY + d) = a \\cdot c \\cdot Cov(X, Y)\n",
    "$\n",
    "- Covariance de la Somme de Variables :\n",
    "$\n",
    "Cov(X_1 + X_2, Y) = Cov(X_1, Y) + Cov(X_2, Y)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recherche de la variance du portefeuille\n",
    "\n",
    "### Rappel des variables : \n",
    "\n",
    "- $(N_{indice})$ : Nombre total d'actions dans l'indice\n",
    "- $(N_{portefeuille})$ : Nombre total d'actions dans le portefeuille\n",
    "- $(n_{BigCap})$ : Nombre total de \"Big Cap\" dans l'indice\n",
    "- $(p_h)$ : Probabilité de hausse.\n",
    "- $(p_{pc})$ : Probabilité de prédiction correcte.\n",
    "- $(w)$ : Poids d'une \"Big Cap\" dans l'indice\n",
    "- $(r)$ : Rendement (Pour simplifier nos calculs, ici on va dire qu'une hausse vaut $r$ et une baisse $-r$).\n",
    "- $(x)$ : Variable de sur-pondération du poids d'une \"Big Cap\".\n",
    "- $(y)$ : Variable de sous-pondération du poids d'une \"Big Cap\".\n",
    "\n",
    "### Contexte :\n",
    "- Il n'y a pas de covariance entre les Small Cap et les Big Cap dans l'indice. Cela a été démontré précédemment. Les rendements des Small Cap et des Big Cap ne sont pas dépendants, donc si il n'y a pas d'ajustements fait sur les poids, il n'y a pas de dépendance.\n",
    "\n",
    "- Il n'y a pas de covariance entre la variance des Small Cap et et la variance de l'ajustement du poids de la poche des Big Cap.\n",
    "\n",
    "- Hors il y a une covariance entre la variance de la poche Small Cap \"Ajustée\", et la poche Big Cap. Cette covariance vient de notre ajustement de la taille de la poche Small Cap. Cette ajustement dépend de nos prédictions sur les Big Cap, donc il est logique qu'on trouve une covariance entre les deux distributions.\n",
    "\n",
    "#### Pour facilité la compréhension et l'écriture du problème, Nous allons supposer trois distributions : \n",
    "\n",
    "- $E(X) = E(R_{sc})_{Total}$ Soit l'espérance de rendement des Small Cap avant ajustement par la taille de la poche Big Cap\n",
    "\n",
    "- $E(W) = E(W_{sc})$ Soit l'espérance du poids d'ajustement de la poche Small Cap, dépendant de la taille de la poche Big Cap\n",
    "\n",
    "- $E(Y) = E(R_{bc})_{Total}$ Soit l'espérance de rendement des Big Cap\n",
    "\n",
    "#### On rappel leurs équations : \n",
    "\n",
    "- $E(X) = \\left( \\frac{p_h \\times p_{pc}}{p_h \\times p_{pc} + (1 - p_h) \\times (1 - p_{pc})} \\right) \\cdot r_h + \\left( \\frac{(1 - p_h) \\times (1 - p_{pc})}{p_h \\times p_{pc} + (1 - p_h) \\times (1 - p_{pc})} \\right) \\cdot r_b $\n",
    "\n",
    "- $E(W) = 1 - n_{bc} \\cdot (w_{bc} + [p_h \\cdot p_{pc} + (1 - p_h) \\cdot (1 - p_{pc})] \\cdot x - [p_h \\cdot (1 - p_{pc}) + (1 - p_h) \\cdot p_{pc}] \\cdot y)$\n",
    "\n",
    "- $E(Y) = [p_h \\cdot r_h \\cdot (p_{pc} \\cdot (w + x) + (1 - p_{pc}) \\cdot (w - y)) - (1 - p_h) \\cdot r_b \\cdot (p_{pc} \\cdot (w - y) + (1 - p_{pc}) \\cdot (w + x))] \\times n_{BigCap}$\n",
    "\n",
    "### Problème : \n",
    "\n",
    "On veut obtenir la variance de notre portefeuille. on connait son Espérance : \n",
    "$$E(R_{ptf}) = E(X) * E(W) + E(Y)$$\n",
    "Sa variance se définit : \n",
    "$$Var(R_{ptf}) = Var(X \\times W + Y)$$\n",
    "\n",
    "$$Var(X \\times W + Y) = Var(X \\times W) + Var(Y) + 2 Cov(X \\cdot W, Y)$$\n",
    "\n",
    "Hors X et W sont indépendants, alors :\n",
    "\n",
    "$$Var(X \\times W) = E(X)^2 \\times Var(W) + E(W)^2 \\times Var(X) + Var(X) + Var(W)$$\n",
    "\n",
    "donc :\n",
    "\n",
    "$$Var(X \\times W + Y) = E(X)^2 \\times Var(W) + E(W)^2 \\times Var(X) + Var(X) + Var(W)  + Var(Y) + 2 Cov(X \\cdot W, Y)$$\n",
    "\n",
    "Il nous reste donc à définir la covariance : \n",
    "$$Cov(X \\cdot W, Y) = E((X \\cdot W) \\cdot Y) - E(X \\cdot W)E(Y)$$ \n",
    "\n",
    "Hors X et W sont indépendants, donc $E(X \\cdot W) = E(X)E(W)$ : \n",
    "\n",
    "$$Cov(X \\cdot W, Y) = E(X \\cdot W \\cdot Y) - E(X)E(W)E(Y)$$\n",
    "\n",
    "Comme expliqué dans le contexte, on suppose X indépendant de W et de Y, et W et Y dépendants. Alors : \n",
    "\n",
    "$$E(X \\cdot W \\cdot Y) = E(X \\cdot (W \\cdot Y)) = E(X) E(W \\cdot Y)$$\n",
    "\n",
    "On a peut donc définir la covariance tel que : \n",
    "\n",
    "$$Cov(X \\cdot W, Y) = E(X)E(W \\cdot Y) - E(X)E(W)E(Y)$$\n",
    "\n",
    "Voici la formule finale de la variance : \n",
    "\n",
    "$$Var(X \\times W + Y) = E(X)^2 \\times Var(W) + E(W)^2 \\times Var(X) + Var(X) + Var(W)  + Var(Y) + 2[E(X)E(W \\cdot Y) - E(X)E(W)E(Y)]$$\n",
    "\n",
    "La seule inconnu dans cette équation est $E(W \\cdot Y)$, il nous reste donc à la définir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour une Big Cap, soit $n_{bc} = 1$, le calcul est relativement simple. Pour rappel nous sur-pondérons de $x$ si on croit à une hausse, et on sous-pondère de $y$ si on croit à une baisse. Nous avons quatre possibilités : \n",
    "\n",
    "- Nous avons une hausse et nous prédisons correctement, soit $p_h \\times p_{pc}$. nous avons $r_h \\cdot (w_{bc} + x) \\cdot (1 - (w_{bc} + x))$\n",
    "- Nous avons une hausse et nous prédisons mal, soit $p_h \\times (1 - p_{pc})$. nous avons $r_h \\cdot (w_{bc} - y) \\cdot (1 - (w_{bc} - y))$\n",
    "- Nous avons une baisse et nous prédisons correctement, soit $(1 - p_h) \\times p_{pc}$. nous avons $r_b \\cdot (w_{bc} - y) \\cdot (1 - (w_{bc} - y))$\n",
    "- Nous avons une baisse et nous prédisons mal, soit $(1 - p_h) \\times (1 - p_{pc})$. nous avons $r_b \\cdot (w_{bc} + x) \\cdot (1 - (w_{bc} + x))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ppc=0.8\n",
    "ph=0.4\n",
    "rh=1\n",
    "rb=-10\n",
    "\n",
    "N_indice=100\n",
    "n_bigcap=2\n",
    "w_bigcap=0.3\n",
    "N_ptf=30\n",
    "\n",
    "x=0.05\n",
    "y=0.1\n",
    "\n",
    "n_simulations = 10000\n",
    "results = [simulate_portfolio(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y) for _ in range(n_simulations)]\n",
    "\n",
    "# Conversion des résultats en DataFrame\n",
    "df = pd.DataFrame(results, columns=['Rendement Indice', 'Rendement Portefeuille','Poids','BigCap Portefeuille','SmallCap Portefeuille','BigCap Indice','SmallCap Indice','E_x_total', 'W_sc', 'E_WY'])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Espérance simulée de Y*Z :  -1.2497880000000003\n",
      "Espérance théorique de Y*Z :  -1.9107999999999996\n"
     ]
    }
   ],
   "source": [
    "\n",
    "term1 = ph * ppc * rh * (w_bigcap + x) * (1 - (w_bigcap + x))\n",
    "term2 = ph * (1 - ppc) * rh * (w_bigcap - y) * (1 - (w_bigcap - y))\n",
    "term3 = (1 - ph) * ppc * rb * (w_bigcap - y) * (1 - (w_bigcap - y)) \n",
    "term4 = (1 - ph) * (1 - ppc) * rb * (w_bigcap + x) * (1 - (w_bigcap + x))\n",
    "\n",
    "result = (term1 + term2 + term3 + term4) * n_bigcap\n",
    "\n",
    "print(\"\\nEspérance simulée de Y*Z : \", (df['BigCap Portefeuille'] * df['W_sc']).mean())\n",
    "print(\"Espérance théorique de Y*Z : \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour $n_{bc} > 1$, le sujet devient plus complexe, notre arbre de décision devient bien plus grand et il faut trouver une équation pour le généraliser. \n",
    "\n",
    "Voici une proposition un peu hasardeuse qui se rapproche :\n",
    "\n",
    "_PS : On rappel que $E(X)E(W \\cdot Y)$. Donc quand notre espérance de rendement $E(X)$ est élevé, un léger écart de $E(W \\cdot Y)$ par rapport à sa valeur réel va être démultiplié par $E(X)$. Il est donc important de trouver l'équation exacte._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Espérance simulée de Y*Z :  -1.2497880000000003\n",
      "Espérance théorique de Y*Z :  -0.8353463039999997\n"
     ]
    }
   ],
   "source": [
    "# Boîte à idées : \n",
    "\n",
    "#W_sc = 1 - n_bigcap * (w_bigcap + (ph * ppc + (1 - ph) * (1 - ppc)) * x - (ph * (1 - ppc) + (1 - ph) * ppc) * y)\n",
    "W_bc = w_bigcap + (ph * ppc + (1 - ph) * (1 - ppc)) * x - (ph * (1 - ppc) + (1 - ph) * ppc) * y\n",
    "\n",
    "#W_bc_rh = w_bigcap + (ph * ppc) * x - (ph * (1 - ppc)) * y\n",
    "#W_bc_rb = w_bigcap + ((1 - ph) * (1 - ppc)) * x - ((1 - ph) * ppc) * y\n",
    "\n",
    "W_bc_rh_x = w_bigcap + (ph * ppc) * x\n",
    "W_bc_rh_y = w_bigcap - (ph * (1 - ppc)) * y\n",
    "W_bc_rb_x = w_bigcap + ((1 - ph) * (1 - ppc)) * x \n",
    "W_bc_rb_y = w_bigcap - ((1 - ph) * ppc) * y\n",
    "\n",
    "# Proposition proche de la solution\n",
    "\n",
    "term1 = ph * ppc * (w_bigcap + x) * rh * (1 - W_bc_rh_x) \n",
    "term2 = ph * (1 - ppc) * (w_bigcap - y) * rh  * (1 - W_bc_rh_y) \n",
    "term3 = (1 - ph) * ppc * (w_bigcap - y) * rb * (1 - W_bc_rb_x) \n",
    "term4 = (1 - ph) * (1 - ppc) * (w_bigcap + x) * rb * (1 - W_bc_rb_y) \n",
    "\n",
    "result = (term1 + term2 + term3 + term4) * n_bigcap * (1 - n_bigcap * W_bc)\n",
    "\n",
    "print(\"\\nEspérance simulée de Y*Z : \", (df['BigCap Portefeuille'] * df['W_sc']).mean())\n",
    "print(\"Espérance théorique de Y*Z : \", result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut utiliser l'outil de visualisation suivant pour voir si on colle avec la simulation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Simulée | Théorique\n",
      "\n",
      "                E(WY) :  -1.24979 -0.83535\n",
      "\n",
      "                 E(X) :  -2.00027 -2.0\n",
      "\n",
      "   E(XWY) = E(X)E(WY) :  2.49992 1.67069\n",
      "\n",
      "         E(X)E(W)E(Y) :  2.34958 2.34374\n",
      "\n",
      "E(XWY) - E(X)E(W)E(Y) :  0.15033 -0.67305\n",
      "\n",
      "      Réel Covariance :  0.16447\n"
     ]
    }
   ],
   "source": [
    "# Détail des variables pour le calcul de la variance du portefeuille\n",
    "\n",
    "digit = 5\n",
    "\n",
    "# Définition de certaines variables :\n",
    "\n",
    "E_R_sc_ptf_total = smallcap_ptf(ppc=ppc, ph=ph, rh=rh, rb=rb, N_indice=N_indice, n_bigcap=n_bigcap, w_bigcap=w_bigcap, N_ptf=N_ptf, x=x, y=y)[2]\n",
    "\n",
    "E_R_bc_total = bigcap(ppc=ppc, ph=ph, rh=rh, rb=rb, N_indice=N_indice, n_bigcap=n_bigcap, w_bigcap=w_bigcap, N_ptf=N_ptf, x=x, y=y)[0]\n",
    "\n",
    "W_sc = 1 - n_bigcap * (w_bigcap + (ph * ppc + (1 - ph) * (1 - ppc)) * x - (ph * (1 - ppc) + (1 - ph) * ppc) * y)\n",
    "\n",
    "# Détail des calculs\n",
    "\n",
    "print(\"                        Simulée | Théorique\")\n",
    "\n",
    "print(\"\\n                E(WY) : \", round((df['BigCap Portefeuille'] * df['W_sc']).mean(), digit), round(result, digit))\n",
    "\n",
    "print(\"\\n                 E(X) : \", round(df['SmallCap Portefeuille'].mean()/df['W_sc'].mean(), digit), round(E_R_sc_ptf_total, digit))\n",
    "\n",
    "print(\"\\n   E(XWY) = E(X)E(WY) : \", round(df['SmallCap Portefeuille'].mean()/df['W_sc'].mean() * (df['BigCap Portefeuille'] * df['W_sc']).mean(), digit), round(E_R_sc_ptf_total * result, digit))\n",
    "\n",
    "print(\"\\n         E(X)E(W)E(Y) : \", round(df['SmallCap Portefeuille'].mean() * df['BigCap Portefeuille'].mean(), digit), round(E_R_sc_ptf_total * W_sc * E_R_bc_total, digit))\n",
    "\n",
    "print(\"\\nE(XWY) - E(X)E(W)E(Y) : \", round((df['SmallCap Portefeuille'].mean()/df['W_sc'].mean() * (df['BigCap Portefeuille'] * df['W_sc']).mean()) - df['SmallCap Portefeuille'].mean() * df['BigCap Portefeuille'].mean(),digit), round(E_R_sc_ptf_total * result - E_R_sc_ptf_total * W_sc * E_R_bc_total, digit))\n",
    "\n",
    "print(\"\\n      Réel Covariance : \", round(df['SmallCap Portefeuille'].cov(df['BigCap Portefeuille']), digit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORK IN PROGRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 54\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_bigcap \u001b[38;5;129;01min\u001b[39;00m n_values:\n\u001b[0;32m     53\u001b[0m     n_simulations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m---> 54\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43msimulate_portfolio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mppc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mppc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mph\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_indice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mN_indice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_bigcap\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_bigcap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_bigcap\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mw_bigcap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_ptf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mN_ptf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_simulations\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Conversion des résultats en DataFrame\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRendement Indice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRendement Portefeuille\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPoids\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBigCap Portefeuille\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSmallCap Portefeuille\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBigCap Indice\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSmallCap Indice\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE_x_total\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE_W_sc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE_WY\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[91], line 54\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_bigcap \u001b[38;5;129;01min\u001b[39;00m n_values:\n\u001b[0;32m     53\u001b[0m     n_simulations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m---> 54\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\u001b[43msimulate_portfolio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mppc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mppc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mph\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_indice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mN_indice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_bigcap\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_bigcap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_bigcap\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mw_bigcap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_ptf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mN_ptf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_simulations)]\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Conversion des résultats en DataFrame\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRendement Indice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRendement Portefeuille\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPoids\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBigCap Portefeuille\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSmallCap Portefeuille\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBigCap Indice\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSmallCap Indice\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE_x_total\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE_W_sc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE_WY\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[82], line 142\u001b[0m, in \u001b[0;36msimulate_portfolio\u001b[1;34m(ppc, ph, rh, rb, N_indice, n_bigcap, w_bigcap, N_ptf, x, y)\u001b[0m\n\u001b[0;32m    137\u001b[0m actions_momentum_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(actions_momentum \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \n\u001b[0;32m    138\u001b[0m                                  np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m], size\u001b[38;5;241m=\u001b[39mN_indice, p\u001b[38;5;241m=\u001b[39mprobas), \n\u001b[0;32m    139\u001b[0m                                  np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], size\u001b[38;5;241m=\u001b[39mN_indice, p\u001b[38;5;241m=\u001b[39mprobas))\n\u001b[0;32m    140\u001b[0m actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(N_indice)\n\u001b[1;32m--> 142\u001b[0m df_bigcap_indice \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActions\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mn_bigcap\u001b[49m\u001b[43m]\u001b[49m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReturns\u001b[39m\u001b[38;5;124m'\u001b[39m:returns[:n_bigcap],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMomentum\u001b[39m\u001b[38;5;124m'\u001b[39m:actions_momentum[:n_bigcap],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMomentum_pred\u001b[39m\u001b[38;5;124m'\u001b[39m:actions_momentum_pred[:n_bigcap], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPoids\u001b[39m\u001b[38;5;124m'\u001b[39m:w_bigcap})\n\u001b[0;32m    143\u001b[0m df_smallcap_indice \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActions\u001b[39m\u001b[38;5;124m'\u001b[39m:actions[n_bigcap:],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReturns\u001b[39m\u001b[38;5;124m'\u001b[39m:returns[n_bigcap:],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMomentum\u001b[39m\u001b[38;5;124m'\u001b[39m:actions_momentum[n_bigcap:],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMomentum_pred\u001b[39m\u001b[38;5;124m'\u001b[39m:actions_momentum_pred[n_bigcap:], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPoids\u001b[39m\u001b[38;5;124m'\u001b[39m:w_smallcap_indice})\n\u001b[0;32m    144\u001b[0m df_indice \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_bigcap_indice, df_smallcap_indice])\n",
      "\u001b[1;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ppc=0.6\n",
    "ph=0.5\n",
    "rh=1\n",
    "rb=-1\n",
    "\n",
    "test_values = np.linspace(0, 1, 11)\n",
    "n_values = np.linspace(0, 3, 4)\n",
    "w_values = np.linspace(0, 0.4, 11)\n",
    "rh_values = np.linspace(0, 10, 11)\n",
    "rb_values = np.linspace(0, -10, 11)\n",
    "\n",
    "N_indice=100\n",
    "n_bigcap=3\n",
    "w_bigcap=0.1\n",
    "N_ptf=30\n",
    "\n",
    "x=0.05\n",
    "y=0.1\n",
    "\n",
    "variances_sim_E_WY_ph = []\n",
    "variances_sim_cov_ph = []\n",
    "\n",
    "\n",
    "for ph in test_values:\n",
    "    n_simulations = 1000\n",
    "    results = [simulate_portfolio(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y) for _ in range(n_simulations)]\n",
    "\n",
    "    # Conversion des résultats en DataFrame\n",
    "    df = pd.DataFrame(results, columns=['Rendement Indice', 'Rendement Portefeuille','Poids','BigCap Portefeuille','SmallCap Portefeuille','BigCap Indice','SmallCap Indice','E_x_total', 'E_W_sc', 'E_WY'])\n",
    "    variances_sim_sc_ph.append(df['SmallCap Portefeuille'].var())\n",
    "    variances_sim_cov_ph.append(df['Rendement Portefeuille'].var())\n",
    "\n",
    "ph = 0.5\n",
    "\n",
    "variances_sim_E_WY_ppc = []\n",
    "variances_sim_cov_ppc = []\n",
    "\n",
    "for ppc in test_values:\n",
    "    n_simulations = 1000\n",
    "    results = [simulate_portfolio(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y) for _ in range(n_simulations)]\n",
    "\n",
    "    # Conversion des résultats en DataFrame\n",
    "    df = pd.DataFrame(results, columns=['Rendement Indice', 'Rendement Portefeuille','Poids','BigCap Portefeuille','SmallCap Portefeuille','BigCap Indice','SmallCap Indice','E_x_total', 'E_W_sc', 'E_WY'])\n",
    "    variances_sim_E_WY_ppc.append(df['SmallCap Portefeuille'].var())\n",
    "    variances_sim_cov_ppc.append(df['Rendement Portefeuille'].var())\n",
    "\n",
    "ppc = 0.6\n",
    "\n",
    "variances_sim_E_WY_n = []\n",
    "variances_sim_cov_n = []\n",
    "\n",
    "for n_bigcap in n_values:\n",
    "    n_simulations = 1000\n",
    "    results = [simulate_portfolio(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y) for _ in range(n_simulations)]\n",
    "\n",
    "    # Conversion des résultats en DataFrame\n",
    "    df = pd.DataFrame(results, columns=['Rendement Indice', 'Rendement Portefeuille','Poids','BigCap Portefeuille','SmallCap Portefeuille','BigCap Indice','SmallCap Indice','E_x_total', 'E_W_sc', 'E_WY'])\n",
    "    variances_sim_E_WY_n.append(df['SmallCap Portefeuille'].var())\n",
    "    variances_sim_cov_n.append(df['Rendement Portefeuille'].var())\n",
    "\n",
    "n_bigcap = 3\n",
    "\n",
    "variances_sim_E_WY_w = []\n",
    "variances_sim_ptf_w = []\n",
    "\n",
    "for w in w_values:\n",
    "    n_simulations = 1000\n",
    "    results = [simulate_portfolio(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y) for _ in range(n_simulations)]\n",
    "\n",
    "    # Conversion des résultats en DataFrame\n",
    "    df = pd.DataFrame(results, columns=['Rendement Indice', 'Rendement Portefeuille','Poids','BigCap Portefeuille','SmallCap Portefeuille','BigCap Indice','SmallCap Indice','E_x_total', 'E_W_sc', 'E_WY'])\n",
    "    variances_sim_E_WY_w.append(df['SmallCap Portefeuille'].var())\n",
    "    variances_sim_cov_w.append(df['Rendement Portefeuille'].var())\n",
    "\n",
    "WindowsError = 0.1\n",
    "\n",
    "variances_sim_E_WY_rh = []\n",
    "variances_sim_cov_rh = []\n",
    "\n",
    "for rh in rh_values:\n",
    "    n_simulations = 1000\n",
    "    results = [simulate_portfolio(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y) for _ in range(n_simulations)]\n",
    "\n",
    "    # Conversion des résultats en DataFrame\n",
    "    df = pd.DataFrame(results, columns=['Rendement Indice', 'Rendement Portefeuille','Poids','BigCap Portefeuille','SmallCap Portefeuille','BigCap Indice','SmallCap Indice','E_x_total', 'E_W_sc', 'E_WY'])\n",
    "    variances_sim_E_WY_rh.append(df['SmallCap Portefeuille'].var())\n",
    "    variances_sim_cov_rh.append(df['Rendement Portefeuille'].var())\n",
    "\n",
    "rh = 1\n",
    "\n",
    "variances_sim_E_WY_rb = []\n",
    "variances_sim_cov_rb = []\n",
    "\n",
    "for rb in rb_values:\n",
    "    n_simulations = 1000\n",
    "    results = [simulate_portfolio(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y) for _ in range(n_simulations)]\n",
    "\n",
    "    # Conversion des résultats en DataFrame\n",
    "    df = pd.DataFrame(results, columns=['Rendement Indice', 'Rendement Portefeuille','Poids','BigCap Portefeuille','SmallCap Portefeuille','BigCap Indice','SmallCap Indice','E_x_total', 'E_W_sc', 'E_WY'])\n",
    "    variances_sim_E_WY_rb.append(df['SmallCap Portefeuille'].var())\n",
    "    variances_sim_cov_rb.append(df['Rendement Portefeuille'].var())\n",
    "\n",
    "rb = -1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variances_theo_sc_ph = []\n",
    "variances_theo_ptf_ph = []\n",
    "\n",
    "for ph in test_values:\n",
    "    variances_theo_sc_ph.append(smallcap_ptf(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y)[1])\n",
    "    variances_theo_ptf_ph.append(portfolio(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y)[1])\n",
    "\n",
    "ph = 0.5\n",
    "\n",
    "variances_theo_sc_ppc = []\n",
    "variances_theo_ptf_ppc = []\n",
    "\n",
    "for ppc in test_values:\n",
    "    variances_theo_sc_ppc.append(smallcap_ptf(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y)[1])\n",
    "    variances_theo_ptf_ppc.append(portfolio(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y)[1])\n",
    "\n",
    "ppc = 0.6\n",
    "\n",
    "variances_theo_sc_x = []\n",
    "variances_theo_ptf_x = []\n",
    "\n",
    "for x in test_values:\n",
    "    variances_theo_sc_x.append(smallcap_ptf(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y)[1])\n",
    "    variances_theo_ptf_x.append(portfolio(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y)[1])\n",
    "\n",
    "x = 0.05\n",
    "\n",
    "variances_theo_sc_y = []\n",
    "variances_theo_ptf_y = []\n",
    "\n",
    "for y in test_values:\n",
    "    variances_theo_sc_y.append(smallcap_ptf(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y)[1])\n",
    "    variances_theo_ptf_y.append(portfolio(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y)[1])\n",
    "\n",
    "y = 0.1\n",
    "\n",
    "variances_theo_sc_rh = []\n",
    "variances_theo_ptf_rh = []\n",
    "\n",
    "for rh in test_values:\n",
    "    variances_theo_sc_rh.append(smallcap_ptf(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y)[1])\n",
    "    variances_theo_ptf_rh.append(portfolio(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y)[1])\n",
    "\n",
    "rh = 1\n",
    "\n",
    "variances_theo_sc_rb = []\n",
    "variances_theo_ptf_rb = []\n",
    "\n",
    "for rb in test_values:\n",
    "    variances_theo_sc_rb.append(smallcap_ptf(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y)[1])\n",
    "    variances_theo_ptf_rb.append(portfolio(ppc = ppc, ph = ph, rh = rh, rb = rb, N_indice = N_indice, n_bigcap = n_bigcap, w_bigcap = w_bigcap, N_ptf = N_ptf, x = x, y = y)[1])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
